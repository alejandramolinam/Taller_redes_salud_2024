[
  {
    "objectID": "02-redes-aleatorias.html#formación-de-redes-modelos-nulos",
    "href": "02-redes-aleatorias.html#formación-de-redes-modelos-nulos",
    "title": "3  Formación de redes: modelos de generación de redes aleatorias",
    "section": "3.1 Formación de Redes: Modelos Nulos",
    "text": "3.1 Formación de Redes: Modelos Nulos"
  },
  {
    "objectID": "02-redes-aleatorias.html#librerías",
    "href": "02-redes-aleatorias.html#librerías",
    "title": "3  Formación de redes: modelos de generación de redes aleatorias",
    "section": "3.2 Librerías",
    "text": "3.2 Librerías\n\nlibrary(igraph)\nlibrary(dplyr)"
  },
  {
    "objectID": "02-redes-aleatorias.html#base-de-datos",
    "href": "02-redes-aleatorias.html#base-de-datos",
    "title": "3  Formación de redes: modelos de generación de redes aleatorias",
    "section": "3.3 Base de Datos",
    "text": "3.3 Base de Datos\nCargamos los datos del archivo de texto, que contiene una columna con los nodos emisores, otra con los nodos receptores y otra columna con el atributo “n” de cada enlace.\n\nlinks &lt;- read.csv(\"datos/movements.csv\", header=T, as.is=T) \nhead(links) \n\n  source target  n\n1 ward_1 ward_2 10\n2 ward_1 ward_3 50\n3 ward_1 ward_4 80\n4 ward_2 ward_1 50\n5 ward_2 ward_3 80\n6 ward_2 ward_4 10\n\n\n\n# Convirtiendo los datos a un objeto de igraph: \nnet &lt;- graph_from_data_frame(links, directed=T)  \n\n\n3.3.1 Erdos-Renyi:\n\n######## veamos la versi?n Erdos-Renyi de nuestra red ######## \n# erdos.renyi.game(n, p.or.m, type = c(\"gnp\", \"gnm\"), directed = FALSE, loops = FALSE, ...)\n# n: The number of vertices in the graph.\n# p.or.m: Either the probability for drawing an edge between two arbitrary vertices (G(n,p) graph), or the number of edges in the graph (for G(n,m) graphs).\n# type: The type of the random graph to create, either gnp (G(n,p) graph) or gnm (G(n,m) graph).\n# directed: Logical, whether the graph will be directed, defaults to FALSE.\n# loops: Logical, whether to add loop edges, defaults to FALSE.\n\n\nsize &lt;- length(V(net))\ndens &lt;- graph.density(net) # probabilidad de un link\n\ner &lt;- erdos.renyi.game(size, dens)\n\ner.grado &lt;- degree(er)\ner.distancia &lt;- round(mean_distance(er),3)\ner.clustering &lt;- round(transitivity(er, type=\"global\"),3)\n\nV(er)$size &lt;- er.grado*1.5\nV(er)$frame.color &lt;- \"white\"\nV(er)$color &lt;- \"orange\"\nV(er)$label &lt;- V(net)\nE(er)$arrow.mode &lt;- 1\nE(er)$arrow.size &lt;- 0.2\nl &lt;- layout_with_fr(er)\nplot(er, main=\"Erdös-Renyi\", layout=l)\n\n\n\n\n\nprint(\"Erdos-Renyi\")\n\n[1] \"Erdos-Renyi\"\n\nmean(er.grado)\n\n[1] 2.666667\n\ner.distancia\n\n[1] 2.212\n\ner.clustering\n\n[1] 0.1\n\nprint(\"Red real\")\n\n[1] \"Red real\"\n\nnet.degree&lt;-degree(net)\nnet.distancia &lt;- round(mean_distance(net),3) \nnet.clustering &lt;- round(transitivity(net, type=\"global\"),3)\n\nmean(net.degree)\n\n[1] 5.833333\n\nnet.distancia\n\n[1] 2.614\n\nnet.clustering\n\n[1] 0.673\n\n\n\n\n3.3.2 Strogats-Watts (mundo pequeño):\n\n########  veamos la versi?n Strogatz-Watts de nuestra red ######## MUNDOS PEQUE?OS\n# sample_smallworld(dim, size, nei, p, loops = FALSE, multiple = FALSE)\n# dim: Integer constant, the dimension of the starting lattice.\n# size: Integer constant, the size of the lattice along each dimension.\n# nei: Integer constant, the neighborhood within which the vertices of the lattice will be connected.\n# p: Real constant between zero and one, the rewiring probability.\n# loops: Logical scalar, whether loops edges are allowed in the generated graph.\n# multiple: Logical scalar, whether multiple edges are allowed int the generated graph.\n\n# parametros: tama?o (size), minima cantidad de conexiones (3 - triada), rewiring (0.1) pq se parte de una red regular\nsm &lt;- watts.strogatz.game(1,size,3,0.1) # estoy asumiendo vecindarios de 3 nodos y rewiring de 0.1 (se puede mejorar la precisión)\nsm.grado &lt;- degree(sm)\n\nV(sm)$size &lt;- sm.grado*1.5\nV(sm)$frame.color &lt;- \"white\"\nV(sm)$color &lt;- \"orange\"\nV(sm)$label &lt;- V(net)\nE(sm)$arrow.mode &lt;- 1\nE(sm)$arrow.size &lt;- 0.2\nl &lt;- layout_with_fr(sm)\nplot(sm, main=\"Strogatz-Watts\", layout=l)\n\n\n\nsm.distancia &lt;- round(mean_distance(sm),3)\nsm.clustering &lt;- round(transitivity(sm, type=\"global\"),3)\n\n\n\n3.3.3 Barabasi (libre de escala):\n\n########  veamos la version Barabasi de nuestra red ######## \n# sample_pa(n, power = 1, m = NULL, out.dist = NULL, out.seq = NULL,\n#      out.pref = FALSE, zero.appeal = 1, directed = TRUE,\n#      algorithm = c(\"psumtree\", \"psumtree-multiple\", \"bag\"),\n#      start.graph = NULL)\n# n; Number of vertices.\n# power: The power of the preferential attachment, the default is one, ie. linear\n# m: Numeric constant, the number of edges to add in each time step.\n# out.dist: Numeric vector, the distribution of the number of edges to add in each time step. This argument is only used if the out.seq argument is omitted or NULL.\n# out.seq: Numeric vector giving the number of edges to add in each time step. Its first element is ignored as no edges are added in the first time step.\n# out.pref: Logical, if true the total degree is used for calculating the citation probability, otherwise the in-degree is used.\n# zero.appeal: The 'attractiveness' of the vertices with no adjacent edges. See details below.\n# directed: Whether to create a directed graph.\n# algorithm: The algorithm to use for the graph generation.\n# start.graph: ... If a graph, then the supplied graph is used as a starting graph for the preferential attachment algorithm. \npa &lt;- barabasi.game(size,power=1, m=2, directed=F, algorithm=\"psumtree\") \npa.grado &lt;- degree(pa)\n\nV(pa)$size &lt;- pa.grado*1.5\nV(pa)$frame.color &lt;- \"white\"\nV(pa)$color &lt;- \"orange\"\nV(pa)$label &lt;- V(net)\nE(pa)$arrow.mode &lt;- 1\nE(pa)$arrow.size &lt;- 0.2\nl &lt;- layout_with_fr(pa)\nplot(pa, main=\"Strogatz-Watts\", layout=l)\n\n\n\npa.distancia &lt;- round(mean_distance(pa),3)\npa.clustering &lt;- round(transitivity(pa, type=\"global\"),3)\n\n\n\n3.3.4 Comparación\nComparemos los 3 modelos nulos con la red real:\n\nresumen &lt;- matrix(c(net.distancia,net.clustering, \n  er.distancia, er.clustering,\n  sm.distancia,sm.clustering,\n  pa.distancia,pa.clustering),\n  nrow=2,ncol=4,byrow=F)\nrownames(resumen) &lt;- c(\"distancia\",\"clustering\")\ncolnames(resumen) &lt;- c(\"Real\",\"ER\",\"SW\",\"PA\")\nresumen\n\n            Real    ER    SW    PA\ndistancia  2.614 2.212 1.470 1.818\nclustering 0.673 0.100 0.561 0.227"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Home",
    "section": "Introduction",
    "text": "Introduction\nIf you are reading this, it is because you know that networks are everywhere. Network science is a rapidly growing field that has been applied to many different disciplines, from biology to sociology, from computer science to physics. In this course, we will go over advanced network science topics; particularly, statistical inference in networks. The course contents are:\n\nOverview of statistical inference.\nIntroduction to network science inference.\nMotif detection.\nGlobal statistics (e.g., modularity).\nRandom graphs (static).\nRandom graphs (dynamic).\nCoevolution of networks and behavior.\nAdvanced topics (sampling and conditional models)."
  },
  {
    "objectID": "01-descripcion-redes.html",
    "href": "01-descripcion-redes.html",
    "title": "2  Descripción de la estructura de una red",
    "section": "",
    "text": "3 Tutorial de análisis de redes\nEn este tutorial veremos algunos conceptos y herramientas básicas para describir y analizar una red usando el paquete igraph para R."
  },
  {
    "objectID": "01-descripcion-redes.html#librerías",
    "href": "01-descripcion-redes.html#librerías",
    "title": "2  Descripción de la estructura de una red",
    "section": "2.1 Librerías",
    "text": "2.1 Librerías\n\nlibrary(igraph)\n\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:igraph':\n\n    as_data_frame, groups, union\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "01-descripcion-redes.html#base-de-datos",
    "href": "01-descripcion-redes.html#base-de-datos",
    "title": "2  Descripción de la estructura de una red",
    "section": "2.2 Base de Datos",
    "text": "2.2 Base de Datos\nLos elementos básicos de una red son un conjunto de Nodos y un conjunto de Enlaces.\n\nNodos: cada componente individual de una red. El tamaño de la red será el número total de nodos que la componen.\nEnlaces: Interacciones entre los nodos de la red. Se representan como pares de nodos. Pueden ser dirigidos (nodo emisor -&gt; nodo receptor) o no dirigidos (nodo 1 &lt;-&gt; nodo 2). Un nodo puede tener enlaces con uno o varios otros nodos, o con ninguno.\n\nEn este ejercicio vamos a usar una base de datos ficticia que va a simular una red de derivaciones de pacientes entre centros. Cada nodo será un centro de salud y cada centro estará enlazado con otro cuando uno de ellos haya derivado pacientes hacia el otro, por lo tanto tenemos una red dirigida (centro emisor -&gt; centro receptor).\n\n2.2.1 Atributos\nEn una red, tanto los nodos como los enlaces pueden tener características que los describan (por ejemplo podríamos tener algún atributo de cada centro, como el número total de población que atiende, el número de funcionarios, presupuesto anual, etc; o los enlaces podrían caracterizarse por el número de pacientes promedio diario que derivan, el traspaso de recursos de un centro a otro, etc). En el caso de este ejemplo, cada enlace tiene el atributo “n”=número total de pacientes derivados en un año.\nLos enlaces pueden tener distintos pesos, los pesos de los enlaces nos sirven para comparar las relaciones entre los distintos nodos. No es obligatorio que los enlaces tengan peso (puede haber redes en que todos los enlaces tengan igual peso). En este ejercicio usaremos el atributo “n” como el peso de cada enlace.\n\n\n2.2.2 Lectura\nCargamos los datos del archivo de texto, que contiene una columna con los nodos emisores, otra con los nodos receptores y otra columna con el atributo “n” de cada enlace.\n\nlinks &lt;- read.csv(\"datos/movements.csv\", header=T, as.is=T)\nhead(links)\n\n  source target  n\n1    C_1    C_2 10\n2    C_1    C_3 50\n3    C_1    C_4 80\n4    C_2    C_1 50\n5    C_2    C_3 80\n6    C_2    C_4 10\n\n\nAhora vamos a convertir el Data Frame que acabamos de crear en un objeto “igraph” para trabajar con las funciones del paquete.\nLa función graph_from_data_frame puede tener como input el data frame completo, en ese caso leerá las primeras dos columnas como los nodos de input y output y el resto de columnas como atributos de los enlaces. La variable directed la usamos para indicar si es una red dirigida (T: true) o no (F: false).\nOpcionalmente se le puede pasar a la función un vector con los nodos (esto último es útil en caso de que hayan nodos isla, si no se entrega ese vector los nodos los extrae de los enlaces).\nnet &lt;- graph_from_data_frame(dataframe, vertices=vector_nodos, directed=T)\n\n# Convirtiendo los datos a un objeto de igraph:\nnet &lt;- graph_from_data_frame(links, directed=T) \n\nVeamos los componentes de la red:\n\n# Miramos los nodos y enlaces\nV(net) # VERTICES\n\n+ 12/12 vertices, named, from 65cbb1d:\n [1] C_1  C_2  C_3  C_4  C_5  C_6  C_7  C_8  C_9  C_10 C_11 C_12\n\nE(net) # ENLACES\n\n+ 35/35 edges from 65cbb1d (vertex names):\n [1] C_1 -&gt;C_2  C_1 -&gt;C_3  C_1 -&gt;C_4  C_2 -&gt;C_1  C_2 -&gt;C_3  C_2 -&gt;C_4 \n [7] C_2 -&gt;C_5  C_3 -&gt;C_1  C_3 -&gt;C_2  C_3 -&gt;C_4  C_3 -&gt;C_5  C_4 -&gt;C_1 \n[13] C_4 -&gt;C_2  C_4 -&gt;C_3  C_4 -&gt;C_5  C_5 -&gt;C_1  C_5 -&gt;C_2  C_5 -&gt;C_3 \n[19] C_5 -&gt;C_4  C_4 -&gt;C_6  C_6 -&gt;C_4  C_6 -&gt;C_7  C_6 -&gt;C_8  C_7 -&gt;C_6 \n[25] C_7 -&gt;C_8  C_8 -&gt;C_6  C_8 -&gt;C_7  C_3 -&gt;C_9  C_9 -&gt;C_3  C_9 -&gt;C_10\n[31] C_9 -&gt;C_11 C_10-&gt;C_9  C_10-&gt;C_12 C_11-&gt;C_9  C_12-&gt;C_11\n\n\n\n#l = layout.fruchterman.reingold(net)\nset.seed(999)\nl = layout.kamada.kawai(net)\nplot(net, edge.arrow.size=.4, vertex.size = 20, layout=l, vertex.label = c(1:12))\n\n\n\n\nPodemos remover los enlaces repetidos y los enlaces que son de un mismo nodo hacia si mismo (loops):\n\n# Sacamos los loops del grafo:\nnet &lt;- simplify(net, remove.multiple = T, remove.loops = T)\n\n\n\n2.2.3 Matriz de adyacencia\nLa matriz de adyacencia es otra manera de representar una red, es una matriz que tiene en los ejes x e y los nodos de la red y cada valor de la matriz es 1 si existe ese enlace y 0 si no.\n\n# Si lo necesitamos, podemos extraer la lista de enlaces (edgelist) o la matriz desde la red de igraph.\n\nas_adjacency_matrix(net)\n\n12 x 12 sparse Matrix of class \"dgCMatrix\"\n\n\n  [[ suppressing 12 column names 'C_1', 'C_2', 'C_3' ... ]]\n\n\n                            \nC_1  . 1 1 1 . . . . . . . .\nC_2  1 . 1 1 1 . . . . . . .\nC_3  1 1 . 1 1 . . . 1 . . .\nC_4  1 1 1 . 1 1 . . . . . .\nC_5  1 1 1 1 . . . . . . . .\nC_6  . . . 1 . . 1 1 . . . .\nC_7  . . . . . 1 . 1 . . . .\nC_8  . . . . . 1 1 . . . . .\nC_9  . . 1 . . . . . . 1 1 .\nC_10 . . . . . . . . 1 . . 1\nC_11 . . . . . . . . 1 . . .\nC_12 . . . . . . . . . . 1 ."
  },
  {
    "objectID": "01-descripcion-redes.html#descripción-de-redes",
    "href": "01-descripcion-redes.html#descripción-de-redes",
    "title": "2  Descripción de la estructura de una red",
    "section": "2.3 Descripción de redes",
    "text": "2.3 Descripción de redes\n\n2.3.1 Grados de los nodos:\nUna propiedad clave de cada nodo es su grado, que representa el número de enlaces que tiene con otros nodos. Usualmente se denomina con k_i el grado del i-esimo nodo de la red. En una red dirigida vamos a hablar de in-degree para la cantidad de enlaces que llegan dirigidos hacia un nodo, y de out-degree para la cantidad de enlaces que salen desde un nodo hacia otros.\n\nnet.degree&lt;-igraph::degree(net)\nigraph::degree(net)\n\n C_1  C_2  C_3  C_4  C_5  C_6  C_7  C_8  C_9 C_10 C_11 C_12 \n   7    8   10   10    7    6    4    4    6    3    3    2 \n\nigraph::degree(net, mode=\"in\")\n\n C_1  C_2  C_3  C_4  C_5  C_6  C_7  C_8  C_9 C_10 C_11 C_12 \n   4    4    5    5    3    3    2    2    3    1    2    1 \n\nigraph::degree(net, mode=\"out\")\n\n C_1  C_2  C_3  C_4  C_5  C_6  C_7  C_8  C_9 C_10 C_11 C_12 \n   3    4    5    5    4    3    2    2    3    2    1    1 \n\n\nUna medida descriptiva interesante de una red es la distribución de grado, es decir, cuantos nodos tenemos con cada cantidad de enlaces. Esta distribución nos puede dar pistas sobre la estructura de la red (aleatoria, de mundo pequeño, libre escala).\n\n# distribucion de grado\ngrado.dist &lt;- degree_distribution(net)\ngrado.tabla &lt;- matrix(c(seq(0:10),100*grado.dist),byrow=F,ncol=2)\ngrado.tabla &lt;- as.data.frame(grado.tabla)\ncolnames(grado.tabla) &lt;- c(\"Grado\",\"Porcentaje\")\ngrado.tabla\n\n   Grado Porcentaje\n1      1   0.000000\n2      2   0.000000\n3      3   8.333333\n4      4  16.666667\n5      5  16.666667\n6      6   0.000000\n7      7  16.666667\n8      8  16.666667\n9      9   8.333333\n10    10   0.000000\n11    11  16.666667\n\n\n\n\n2.3.2 Densidad\nLa densidad de la red es la proporción de enlaces existentes, se calcula como el número total de enlaces (orden de la red) sobre el número total de enlaces posibles (si todos los nodos estuvieran conectados con todos, es decir, un grafo completo).\n\nnet.densidad &lt;- edge_density(net)\nnet.densidad\n\n[1] 0.2651515\n\n\nPor ejemplo, en ciencias sociales, una red de personas densa podría indicar un mayor capital social de vinculación .\n\n\n2.3.3 Clustering\nEl clustering de un nodo es la densidad del nodo, es decir, el número de enlaces del nodo, dividido por el número total de enlaces que podrían formar los vecinos del nodo entre ellos.\n\nnet.clustering &lt;- round(transitivity(net, type=\"global\"),3)\nnet.clustering\n\n[1] 0.673\n\n\nPor ejemplo, si analizamos una red de personas y nos interesa estudiar contagio, podríamos pensar que un nodo con mayor clustering es un vector más probable de contagio.\nhttps://doi.org/10.3389/fphy.2015.00071\n\n\n2.3.4 Componentes\nUna red puede ser dividida en sub redes o componentes cuando hay grupos de nodos que no son alcanzables por otro grupo. En una componente todos los nodos están enlazados a algún otro nodo.\n\nSi en una red todos los nodos son alcanzables por algún camino se dice que es un grafo completo.\nLa sub red que contiene más nodos se denomina Componente Principal.\n\ncomponentes &lt;- clusters(net)\ncomponentes\n\n$membership\n C_1  C_2  C_3  C_4  C_5  C_6  C_7  C_8  C_9 C_10 C_11 C_12 \n   1    1    1    1    1    1    1    1    1    1    1    1 \n\n$csize\n[1] 12\n\n$no\n[1] 1\n\ng &lt;- which.max(componentes$csize) # identificamos el gigante\nsubred &lt;- induced.subgraph(net, which(componentes$membership == g)) # nos quedamos con el componente gigante\nV(net)\n\n+ 12/12 vertices, named, from 660d02a:\n [1] C_1  C_2  C_3  C_4  C_5  C_6  C_7  C_8  C_9  C_10 C_11 C_12\n\nV(subred)\n\n+ 12/12 vertices, named, from 672f13a:\n [1] C_1  C_2  C_3  C_4  C_5  C_6  C_7  C_8  C_9  C_10 C_11 C_12\n\n\n\n\n2.3.5 Distancias\n\ngsize(net)\n\n[1] 35\n\ngorder(net)\n\n[1] 12\n\n\n\nnet.distancia &lt;- round(mean_distance(net),3) \nnet.distancia\n\n[1] 2.614\n\nshortest_paths(net,\"C_1\",\"C_12\")\n\n$vpath\n$vpath[[1]]\n+ 5/12 vertices, named, from 660d02a:\n[1] C_1  C_3  C_9  C_10 C_12\n\n\n$epath\nNULL\n\n$predecessors\nNULL\n\n$inbound_edges\nNULL\n\n#all_shortest_paths(net,\"ward_1\")\n\n\n\n2.3.6 Censo de triadas\nLas triadas son conjuntos de 3 nodos, que son la “célula” mínima de una red. En una red dirigida existen múltiples maneras en que 3 nodos pueden estar conectados entre sí. Puede ser interesante saber cuantos tipos de triadas de cada tipo (o de alguno en particular) tiene la red.\n\n\ntriad_census(net)\n\n [1]  68  23 102   0   0   1   1   1   0   0  13   0   0   0   3   8\n\n\nLas triadas triangulares son particularmente interesantes para analizar redes sociales, dan cuenta de la fortaleza de los lazos, la estabilidad de los lazos y puede ser un indicador de confianza.\nhttps://doi.org/10.1016/j.socnet.2010.03.004\n\n\n2.3.7 Medidas de Centralidad\nLas medidas de centralidad se utilizan para identificar los nodos más importantes de una red bajo distintos criterios. Las medidas de centralidad más utilizadas son:\n\nCentralidad de Grado (degree centrality) : Está definida como el grado del nodo. Sirve para identificar los nodos más “populares” de la red.\nCentralidad de Intermediación (betweeness centrality): Mide la cantidad de caminos más cortos entre otros dos nodos que pasan por ese nodo.\nCentralidad de Cercanía (closeness centrality): Se calcula como la suma de los caminos más cortos de ese nodo hacia los otros. Esta medida sirve para detectar nodos que pueden difundir información de forma más eficiente.\nCentralidad de Vector Propio (eigenvector centrality): la centralidad de un nodo es una ponderación de la centralidad de los nodos que lo rodean, es decir, un nodo es más central bajo esta medida si está conectado con otros nodos que también son centrales.\n\nEn este estudio https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7217518/ analizan las distintas medidas de centralidad para determinar nodos críticos en la dispersión de enfermedades infecciosas. En el estudio indican que:\nLos nodos con alta centralidad de grado pueden contagiar a muchas personas, sin embargo, si estos nodos están en la periferia y alejados de los otros nodos de la red, no aportan a la dispersión. Por lo que otras medidas de centralidad también son relevantes de analizar.\nLa centralidad de vector propio ayuda a identificar nodos que están cercanos a varios nodos centrales, estos nodos son personas que de infectares podrían propagar la enfermedad más rápidamente, al igual que los nodos con más centralidad de cercanía.\nLos nodos con alta centralidad de intermediación son nodos que de contagiarse, pueden transmitir la enfermedad a diferentes partes de la red.\nCalculemos las centralidades de nuestra red.\n\n# Calcular grado de centralidad (degree centrality) \ncentralidad_grado &lt;- igraph::degree(net) \n\n# Calcular centralidad de cercanía \ncentralidad_cercania &lt;- igraph::closeness(net, normalized = T) \n\n# Calcular la centralidad de intermediación\ncentralidad_intermediacion &lt;- igraph::betweenness(net, normalized = T)\n\n# Calcular la centralidad de vector propio\ncentralidad_eigen &lt;-igraph::eigen_centrality(net)\n\n\ncentralidades &lt;- cbind(centralidad_grado,\n                       round(centralidad_cercania,3),\n                       round(centralidad_intermediacion,3),\n                       round(centralidad_eigen$vector,3)) \ncolnames(centralidades) &lt;- c(\"grado\", \"cercania\", \"intermediacion\", \"eigen\")\ncentralidades\n\n     grado cercania intermediacion eigen\nC_1      7    0.440          0.000 0.852\nC_2      8    0.458          0.003 0.938\nC_3     10    0.550          0.512 0.997\nC_4     10    0.524          0.439 1.000\nC_5      7    0.458          0.000 0.852\nC_6      6    0.407          0.327 0.306\nC_7      4    0.306          0.000 0.104\nC_8      4    0.306          0.000 0.104\nC_9      6    0.458          0.468 0.291\nC_10     3    0.344          0.091 0.076\nC_11     3    0.324          0.091 0.076\nC_12     2    0.262          0.005 0.019\n\n\nEncontremos ahora los 5 nodos con mayor grado de centralidad de cada tipo:\n\ntop5_degree &lt;- head(sort(centralidad_grado, decreasing = TRUE), 5)\ntop5_betweenness &lt;- head(sort(centralidad_intermediacion, decreasing = TRUE), 5)\ntop5_closeness &lt;- head(sort(centralidad_cercania, decreasing = TRUE), 5)\ntop5_eigenvector &lt;- head(sort(centralidad_eigen$vector, decreasing = TRUE), 5)  # \n\ntop5_degree\n\nC_3 C_4 C_2 C_1 C_5 \n 10  10   8   7   7 \n\ntop5_betweenness\n\n       C_3        C_9        C_4        C_6       C_10 \n0.51212121 0.46818182 0.43939394 0.32727273 0.09090909 \n\ntop5_closeness\n\n      C_3       C_4       C_2       C_5       C_9 \n0.5500000 0.5238095 0.4583333 0.4583333 0.4583333 \n\ntop5_eigenvector\n\n      C_4       C_3       C_2       C_1       C_5 \n1.0000000 0.9970131 0.9380857 0.8519464 0.8519464 \n\n\n\nV(net)$size &lt;- centralidad_grado*1.5\nV(net)$frame.color &lt;- \"white\"\nV(net)$color &lt;- \"orange\"\nV(net)$label &lt;- V(net) \nE(net)$arrow.mode &lt;- 1\nE(net)$arrow.size &lt;- 0.2\n\n\nplot(net, layout=l, main=\"Centralidad de Grado\", vertex.label = c(1:12))\n\n\n\n\n\nV(net)$size &lt;- centralidad_intermediacion*30\nV(net)$frame.color &lt;- \"white\"\nV(net)$color &lt;- \"orange\"\nV(net)$label &lt;- V(net)\nE(net)$arrow.mode &lt;- 1\nE(net)$arrow.size &lt;- 0.2\n\n\nplot(net, layout=l, , main=\"Centralidad de Intermediación\", vertex.label = c(1:12))\n\n\n\n\n\nV(net)$size &lt;- centralidad_cercania*30\nV(net)$frame.color &lt;- \"white\"\nV(net)$color &lt;- \"orange\"\nV(net)$label &lt;- V(net)\nE(net)$arrow.mode &lt;- 1\nE(net)$arrow.size &lt;- 0.2\n\n\nplot(net, layout=l, main=\"Centralidad de Cercanía\", vertex.label = c(1:12))\n\n\n\n\n\nV(net)$size &lt;- centralidad_eigen$vector*20\nV(net)$frame.color &lt;- \"white\"\nV(net)$color &lt;- \"orange\"\nV(net)$label &lt;- V(net)\nE(net)$arrow.mode &lt;- 1\nE(net)$arrow.size &lt;- 0.2\n\n\nplot(net, layout=l, main=\"Centralidad EigenValue\", vertex.label = c(1:12))"
  },
  {
    "objectID": "03-ergm.html#inferencias-en-redes-expected-random-graph-models-ergm",
    "href": "03-ergm.html#inferencias-en-redes-expected-random-graph-models-ergm",
    "title": "4  ERGM: inferencias en la formación de enlaces",
    "section": "4.1 Inferencias en Redes: Expected Random Graph Models (ERGM)",
    "text": "4.1 Inferencias en Redes: Expected Random Graph Models (ERGM)\nEsta metodología permite calcular la probabilidad de un enlace con un modelo que pondera distintos atributos de la red, de los nodos y de los enlaces.\nFunciona con una lógica similar a un modelo “logit” pero en redes."
  },
  {
    "objectID": "03-ergm.html#librerías",
    "href": "03-ergm.html#librerías",
    "title": "4  ERGM: inferencias en la formación de enlaces",
    "section": "4.2 Librerías",
    "text": "4.2 Librerías\n\nlibrary(igraph)\nlibrary(dplyr)\nlibrary(ergm)\nlibrary(sna)\nlibrary(texreg)\nlibrary(intergraph)"
  },
  {
    "objectID": "03-ergm.html#ejemplo-ergm",
    "href": "03-ergm.html#ejemplo-ergm",
    "title": "4  ERGM: inferencias en la formación de enlaces",
    "section": "4.3 Ejemplo: ERGM",
    "text": "4.3 Ejemplo: ERGM\nVamos a usar una red de amistad entre adolescentes simulada (no son datos reales). En esta red cada nodo tiene los atributos de consumo de tabaco y de alcohol.\n\nload('datos/red_adolescentes.Rdata')\n\nnet\n\n Network attributes:\n  vertices = 50 \n  directed = TRUE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = FALSE \n  total edges= 220 \n    missing edges= 0 \n    non-missing edges= 220 \n\n Vertex attribute names: \n    Alcohol Tabaco vertex.names \n\nNo edge attributes\n\n\nVisualicemos esta red marcando con distinto color a las personas que consumen y no consumen cada sustancia:\n\nset.seed(999) \ninet &lt;- intergraph::asIgraph(net)\nl = layout.kamada.kawai(inet)\npar(mfrow=c(1,2))\nV(inet)$color &lt;- ifelse(V(inet)$Alcohol == 1, \"dodgerblue3\",\"seagreen\")\nplot(inet , layout=l, vertex.size = 10, vertex.frame.color = \"black\", vertex.label.cex = .7, vertex.label = NA, edge.curved = .1, edge.arrow.size = .3)\nlegend(\"topleft\", legend=paste('Alcohol',c('Si','No')), pch=21, pt.bg=c(\"dodgerblue3\",\"seagreen\"), horiz = T)\n\n\nV(inet)$color &lt;- ifelse(V(inet)$Tabaco == 1, \"gold\",\"slateblue\")\nplot(inet , layout=l, vertex.size = 10, vertex.frame.color = \"black\", vertex.label.cex = .7, vertex.label = NA, edge.curved = .1, edge.arrow.size = .3)\nlegend(\"topleft\", legend=paste('Tabaco',c('Si','No')), pch=21, pt.bg=c(\"gold\", \"slateblue\"), horiz = T)\n\n\n\n\n\nmod0 &lt;- ergm(net ~ edges)\n\nStarting maximum pseudolikelihood estimation (MPLE):\n\n\nObtaining the responsible dyads.\n\n\nEvaluating the predictor and response matrix.\n\n\nMaximizing the pseudolikelihood.\n\n\nFinished MPLE.\n\n\nEvaluating log-likelihood at the estimate. \n\nmod1 &lt;- ergm(net ~ edges + nodematch(\"Tabaco\") + nodematch(\"Alcohol\"))\n\nStarting maximum pseudolikelihood estimation (MPLE):\nObtaining the responsible dyads.\nEvaluating the predictor and response matrix.\nMaximizing the pseudolikelihood.\nFinished MPLE.\nEvaluating log-likelihood at the estimate. \n\nmod2 &lt;- ergm(net ~ edges + mutual + nodematch(\"Tabaco\") + nodematch(\"Alcohol\"))\n\nStarting maximum pseudolikelihood estimation (MPLE):\nObtaining the responsible dyads.\nEvaluating the predictor and response matrix.\nMaximizing the pseudolikelihood.\nFinished MPLE.\nStarting Monte Carlo maximum likelihood estimation (MCMLE):\nIteration 1 of at most 60:\n\n\nWarning: 'glpk' selected as the solver, but package 'Rglpk' is not available;\nfalling back to 'lpSolveAPI'. This should be fine unless the sample size and/or\nthe number of parameters is very big.\n\n\nOptimizing with step length 1.0000.\nThe log-likelihood improved by 0.0707.\nConvergence test p-value: 0.3043. Not converged with 99% confidence; increasing sample size.\nIteration 2 of at most 60:\nOptimizing with step length 1.0000.\nThe log-likelihood improved by 0.0188.\nConvergence test p-value: 0.0125. Not converged with 99% confidence; increasing sample size.\nIteration 3 of at most 60:\nOptimizing with step length 1.0000.\nThe log-likelihood improved by 0.0403.\nConvergence test p-value: 0.4185. Not converged with 99% confidence; increasing sample size.\nIteration 4 of at most 60:\nOptimizing with step length 1.0000.\nThe log-likelihood improved by 0.0499.\nConvergence test p-value: 0.0066. Converged with 99% confidence.\nFinished MCMLE.\nEvaluating log-likelihood at the estimate. Fitting the dyad-independent submodel...\nBridging between the dyad-independent submodel and the full model...\nSetting up bridge sampling...\nUsing 16 bridges: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 .\nBridging finished.\n\nThis model was fit using MCMC.  To examine model diagnostics and check\nfor degeneracy, use the mcmc.diagnostics() function.\n\nscreenreg(list(mod0,mod1,mod2))\n\n\n========================================================\n                   Model 1      Model 2      Model 3    \n--------------------------------------------------------\nedges                -2.32 ***    -4.32 ***    -4.25 ***\n                     (0.07)       (0.22)       (0.21)   \nnodematch.Tabaco                   1.41 ***     1.12 ***\n                                  (0.19)       (0.18)   \nnodematch.Alcohol                  1.55 ***     1.25 ***\n                                  (0.18)       (0.17)   \nmutual                                          1.81 ***\n                                               (0.24)   \n--------------------------------------------------------\nAIC                1482.12      1324.01      1274.73    \nBIC                1487.92      1341.42      1297.94    \nLog Likelihood     -740.06      -659.01      -633.36    \n========================================================\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05"
  },
  {
    "objectID": "03-ergm.html#section",
    "href": "03-ergm.html#section",
    "title": "4  Taller de redes - parte 3",
    "section": "4.4 ",
    "text": "4.4 \n\nmod0 &lt;- ergm(net ~ edges)\n\nStarting maximum pseudolikelihood estimation (MPLE):\n\n\nObtaining the responsible dyads.\n\n\nEvaluating the predictor and response matrix.\n\n\nMaximizing the pseudolikelihood.\n\n\nFinished MPLE.\n\n\nEvaluating log-likelihood at the estimate. \n\nmod1 &lt;- ergm(net ~ edges + nodematch(\"Tabaco\") + nodematch(\"Alcohol\"))\n\nStarting maximum pseudolikelihood estimation (MPLE):\nObtaining the responsible dyads.\nEvaluating the predictor and response matrix.\nMaximizing the pseudolikelihood.\nFinished MPLE.\nEvaluating log-likelihood at the estimate. \n\nmod2 &lt;- ergm(net ~ edges + mutual + nodematch(\"Tabaco\") + nodematch(\"Alcohol\"))\n\nStarting maximum pseudolikelihood estimation (MPLE):\nObtaining the responsible dyads.\nEvaluating the predictor and response matrix.\nMaximizing the pseudolikelihood.\nFinished MPLE.\nStarting Monte Carlo maximum likelihood estimation (MCMLE):\nIteration 1 of at most 60:\n\n\nWarning: 'glpk' selected as the solver, but package 'Rglpk' is not available;\nfalling back to 'lpSolveAPI'. This should be fine unless the sample size and/or\nthe number of parameters is very big.\n\n\nOptimizing with step length 1.0000.\nThe log-likelihood improved by 0.0707.\nConvergence test p-value: 0.3043. Not converged with 99% confidence; increasing sample size.\nIteration 2 of at most 60:\nOptimizing with step length 1.0000.\nThe log-likelihood improved by 0.0188.\nConvergence test p-value: 0.0125. Not converged with 99% confidence; increasing sample size.\nIteration 3 of at most 60:\nOptimizing with step length 1.0000.\nThe log-likelihood improved by 0.0403.\nConvergence test p-value: 0.4185. Not converged with 99% confidence; increasing sample size.\nIteration 4 of at most 60:\nOptimizing with step length 1.0000.\nThe log-likelihood improved by 0.0499.\nConvergence test p-value: 0.0066. Converged with 99% confidence.\nFinished MCMLE.\nEvaluating log-likelihood at the estimate. Fitting the dyad-independent submodel...\nBridging between the dyad-independent submodel and the full model...\nSetting up bridge sampling...\nUsing 16 bridges: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 .\nBridging finished.\n\nThis model was fit using MCMC.  To examine model diagnostics and check\nfor degeneracy, use the mcmc.diagnostics() function.\n\nscreenreg(list(mod0,mod1,mod2))\n\n\n========================================================\n                   Model 1      Model 2      Model 3    \n--------------------------------------------------------\nedges                -2.32 ***    -4.32 ***    -4.25 ***\n                     (0.07)       (0.22)       (0.21)   \nnodematch.Tabaco                   1.41 ***     1.12 ***\n                                  (0.19)       (0.18)   \nnodematch.Alcohol                  1.55 ***     1.25 ***\n                                  (0.18)       (0.17)   \nmutual                                          1.81 ***\n                                               (0.24)   \n--------------------------------------------------------\nAIC                1482.12      1324.01      1274.73    \nBIC                1487.92      1341.42      1297.94    \nLog Likelihood     -740.06      -659.01      -633.36    \n========================================================\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05"
  },
  {
    "objectID": "index.html#introducción",
    "href": "index.html#introducción",
    "title": "Taller de introducción al análisis de redes",
    "section": "Introducción",
    "text": "Introducción\nLas redes están en todas partes, en estos días distintas disciplinas están utilizando el análisis de redes para poder comprender mejor fenómenos complejos.\nEste taller tiene como objetivo dar una introducción al análisis de redes para motivarlos a aplicar estas metodologías en sus campos de estudio.\nDurante este taller nos enfocaremos en tres temas principales:\n\nDescripción de la estructura de una red\nFormación de redes: modelos de generación de redes aleatorias\nERGM: inferencias en la formación de enlaces"
  },
  {
    "objectID": "02-redes-aleatorias.html#modelos-nulos",
    "href": "02-redes-aleatorias.html#modelos-nulos",
    "title": "3  Formación de redes: modelos de generación de redes aleatorias",
    "section": "3.1 Modelos Nulos",
    "text": "3.1 Modelos Nulos\nAdemás de describir una red, usualmente nos interesa conocer los fenómenos que explican la formación de la estructura específica de una red. Para esto se ocupan los “Modelos Nulos” que son redes formadas de manera aleatoria que preservan alguna propiedad de la red que se quiere estudiar. Luego, se comparan métricas descriptivas de la red sintética con las métricas de la red que estamos estudiando.\nCon esta metodología se intenta buscar las variables más relevantes o los mecanismos que explican su formación.\nHay diversos algoritmos para la creación de un modelo nulo. Uno de los más simples es Erdös Renyi, donde la probabiblidad es igual para cada enlace. En la vida real los niveles de clusterización son generalmente mayores a los observados en las redes aleatorias de Erdos Renyi y tampoco existen hubs en este tipo de redes (hubs: pocos nodos en la red con un grado muy alto).\nPara generar redes aleatorias con una distribución de grado específica, encontramos en la literatura metodologías denominadas General Random Graph Models.\nPor ejemplo, una teoría de la formación de redes es el fenómeno de “mundo pequeño” (Strogats-Watts models), en que la distancia promedio de los nodos es pequeña y no cambia aunque se agreguen nuevos nodos a la red. Por ejemplo: los 6 grados de separación promedio entre 2 personas cualquiera del planeta.\nOtra teoría de formación de redes es la del “preferencial atachment” o tambien llamadas “redes libres de escala”, que se basan en que la probabilidad de generar un enlace es mayor con nodos que tienen mayor grado, en estas redes aparecen naturalmente hubs.\nEn la siguiente figura vemos la red real Interlocking y redes sintéticas generadas por diferentes algoritmos:\n\nGeneremos algunos modelos nulos para nuestro ejemplo:"
  }
]